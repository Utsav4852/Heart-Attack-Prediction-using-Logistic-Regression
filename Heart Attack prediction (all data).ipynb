{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting that person will have Heart Attack or not\n",
    "\n",
    "## Using Logistic Regression\n",
    "\n",
    "<u>Note: It wil works only on binary number.</u>\n",
    "\n",
    "To predict the value of attack we have to first understand the feature of the dataset first. The data includes total 14 columns,\n",
    "1. age\n",
    "2. sex\n",
    "3. chest pain type (4 values)\n",
    "4. resting blood pressure\n",
    "5. serum cholestoral in mg/dl\n",
    "6. fasting blood sugar > 120 mg/dl\n",
    "7. resting electrocardiographic results (values 0,1,2)\n",
    "8. maximum heart rate achieved\n",
    "9. exercise induced angina\n",
    "10. oldpeak = ST depression induced by exercise relative to rest\n",
    "11. the slope of the peak exercise ST segment\n",
    "12. number of major vessels (0-3) colored by flourosopy\n",
    "13. thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n",
    "14. target: 0= less chance of heart attack 1= more chance of heart attack\n",
    "\n",
    "So let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.read_csv('D:/Education/Git hub/datasets_737503_1278636_heart.csv')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal          int64\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see that we have any missing value or not. "
    "Note: If your data have any missing value than you have to replce it with some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = final_df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "False    303\n",
      "Name: age, dtype: int64\n",
      "\n",
      "sex\n",
      "False    303\n",
      "Name: sex, dtype: int64\n",
      "\n",
      "cp\n",
      "False    303\n",
      "Name: cp, dtype: int64\n",
      "\n",
      "trestbps\n",
      "False    303\n",
      "Name: trestbps, dtype: int64\n",
      "\n",
      "chol\n",
      "False    303\n",
      "Name: chol, dtype: int64\n",
      "\n",
      "fbs\n",
      "False    303\n",
      "Name: fbs, dtype: int64\n",
      "\n",
      "restecg\n",
      "False    303\n",
      "Name: restecg, dtype: int64\n",
      "\n",
      "thalach\n",
      "False    303\n",
      "Name: thalach, dtype: int64\n",
      "\n",
      "exang\n",
      "False    303\n",
      "Name: exang, dtype: int64\n",
      "\n",
      "oldpeak\n",
      "False    303\n",
      "Name: oldpeak, dtype: int64\n",
      "\n",
      "slope\n",
      "False    303\n",
      "Name: slope, dtype: int64\n",
      "\n",
      "ca\n",
      "False    303\n",
      "Name: ca, dtype: int64\n",
      "\n",
      "thal\n",
      "False    303\n",
      "Name: thal, dtype: int64\n",
      "\n",
      "target\n",
      "False    303\n",
      "Name: target, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
       "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data\n",
    "\n",
    "To split the data, first we have to store some data into X and y as an Independent values and Dependent values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(final_df[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak']])\n",
    "y = np.asarray(final_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that data is in various format so we have to normalize the data. There are many ways to perform normalisation but here we are using standardscaler from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = StandardScaler().fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape :  (227, 10)\n",
      "Test set shape :  (76, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=2)\n",
    "print(\"Train set shape : \", X_train.shape)\n",
    "print(\"Test set shape : \",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create model\n",
    "\n",
    "As we are using logistic regression we have to create the model. So, now we have to fit the data into model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, solver='liblinear')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=0.01, solver='liblinear').fit(X_train,y_train)\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let's predict the data usig train model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = lr.predict(X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visulise the prediction\n",
    "\n",
    "To visualize the prediction of data, we need to construct confusion matrics. To construct the confusion matrix we have to import an inbuilt library from sklearn.metrics and to plot the confusion matrix we can use either plot_confusion_matrix or seaborn.heatmap. Here, I'm using a heatmap for better colour compression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  8]\n",
      " [ 6 34]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21e02207ac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_hat, labels=[0,1])\n",
    "print(cnf_matrix)\n",
    "\n",
    "sns.heatmap(cnf_matrix, annot=True, cmap='tab20c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate the Accuracy of a model\n",
    "\n",
    "It's important to calculate the score of a model, so we can understand how much our model is capable of. Here, we can see that our model's jaccard_score is almost 71%. And take a look at classification_report which shows the accuracy of 82%.\n",
    "However, Log_loss is showing 48% but there is one unusual thing about log_loss that is if the score of log_loss is less means model prediction is better. The range of the log Los always remains between 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7083333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "print(jaccard_score(y_hat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80        36\n",
      "           1       0.81      0.85      0.83        40\n",
      "\n",
      "    accuracy                           0.82        76\n",
      "   macro avg       0.82      0.81      0.81        76\n",
      "weighted avg       0.82      0.82      0.82        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4837197007826613\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_hat_prob = lr.predict_proba(X_test)\n",
    "print(log_loss(y_test,y_hat_prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
